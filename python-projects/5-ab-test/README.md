# Оценка результатов A/B тестирования

## Описание проекта
На основе данных, предоставленных файлами `ab_project_marketing_events.csv`, `final_ab_events.csv`, `final_ab_new_users.csv`, `final_ab_participants.csv`, дана оценка результату A/B тестирования, проведённого интернет-магазином.

## Навыки и инструменты
* Python
* Pandas
* Plotly
* NumPy
* SciPy
* предобработка данных
* исследовательский анализ
* статистический анализ
* визуализация данных

## Выводы
По воронкам:
* переход пользователей на каждый шаг воронки относительно общего числа пользователей в группе `А` выше, чем в группе `B`;
* доля пользователей, которая доходит от первого события и до оплаты, выше в группе `A` (`31,31%`), чем в группе `B` (`28,21%`)

Статистический тест показал, что есть разница между группами только в событии `product_page`.

И не нужно так заострять внимание на проверке этого теста.

Для начала, по-хорошему, нужно уравнять количество пользователей между группами, провести `A/A` тест, сделать так, чтобы тест проводился НЕ во время различных акций и маркетинговых мероприятий.

А затем можно `A/B` тест провести повторно, чтобы наверняка сказать, действует ли `улучшенная рекомендательная система`.
